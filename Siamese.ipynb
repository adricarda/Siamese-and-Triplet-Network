{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5tuupx-jOXw",
        "colab_type": "text"
      },
      "source": [
        "# Siamese network\n",
        "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much fewer examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
        "\n",
        "Training of  a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-10.\n",
        "\n",
        "Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_P3-X3rb3wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cc96bf1-4d92-43be-ef99-edd87ac70712"
      },
      "source": [
        "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization, merge, concatenate, Activation, Concatenate\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar100\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import TruncatedNormal, RandomNormal\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from itertools import permutations\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7kKOGI0i7ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "# we are only interested in the train data\n",
        "input_size = (32, 32, 3)\n",
        "# embedding_dimensions = 128\n",
        "batch_size = 256\n",
        "num_classes = 100\n",
        "num_train_classes = 80\n",
        "num_test_classes = num_classes - num_train_classes\n",
        "\n",
        "(cifar_x_train, cifar_y_train), (cifar_x_test, cifar_y_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "# reshape output labels\n",
        "cifar_y_train = cifar_y_train.reshape(-1)\n",
        "cifar_y_test = cifar_y_test.reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnHRkKWGi9gE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "de14d8bd-f012-453f-ac74-9b7dc9cfda32"
      },
      "source": [
        "print(cifar_x_train.shape)\n",
        "print(cifar_y_train.shape)\n",
        "print(cifar_x_test.shape)\n",
        "print(cifar_y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000,)\n",
            "(10000, 32, 32, 3)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRf7AUxkFRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split in training set and validation set and sort by category\n",
        "# if we sort by category it is simpler to create batch of data\n",
        "sorted_indices = np.argsort(cifar_y_train)\n",
        "cifar_x_train = cifar_x_train[sorted_indices]\n",
        "cifar_y_train = cifar_y_train[sorted_indices]\n",
        "split_index = np.searchsorted(cifar_y_train, num_train_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG9pmN1Nj84-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f2f9d385-22f3-442e-9821-781410546c91"
      },
      "source": [
        "x_train = cifar_x_train[:split_index]\n",
        "y_train = cifar_y_train[:split_index]\n",
        "\n",
        "# take the last 20 classes as test\n",
        "x_validation = cifar_x_train[split_index:]\n",
        "y_validation = cifar_y_train[split_index:]\n",
        "\n",
        "# NOTE: assumption that the number of samples\n",
        "#       are divisible by the number of classes\n",
        "x_train = x_train.reshape(num_train_classes, x_train.shape[0]//num_train_classes, *x_train.shape[1:])\n",
        "x_validation = x_validation.reshape(num_test_classes, x_validation.shape[0]//num_test_classes, *x_validation.shape[1:])\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_validation.shape)\n",
        "print(y_validation.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 500, 32, 32, 3)\n",
            "(40000,)\n",
            "(20, 500, 32, 32, 3)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYo2Zy1kEM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size, X):\n",
        "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
        "    n_classes, n_examples, w, h, d = X.shape\n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs = [np.zeros((batch_size, h, w, 3)) for i in range(2)]\n",
        "    # initialize vector for the targets, and make one half of it '1's, so 2nd \n",
        "    #half of batch has same class\n",
        "    targets = np.zeros((batch_size,))\n",
        "    targets[batch_size//2:] = 1\n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = np.random.randint(0, n_examples)\n",
        "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, 3)\n",
        "        idx_2 = np.random.randint(0, n_examples)\n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category\n",
        "        else:\n",
        "            #add a random number to the category modulo n_classes to ensure 2nd \n",
        "            #image has different category\n",
        "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, 3)\n",
        "    return pairs, targets\n",
        "\n",
        "def batch_generator(batch_size, X):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size, X)\n",
        "        yield (pairs, targets)\n",
        "\n",
        "def train(model, X_train, batch_size=64, steps_per_epoch=625, epochs=1):\n",
        "    model.fit_generator(batch_generator(batch_size, X_train), \n",
        "                        steps_per_epoch=steps_per_epoch, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfsnRQwfkAco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca32715e-d6eb-40cf-dcd3-2d2b4d0109f8"
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "left_input = Input(input_shape)\n",
        "right_input = Input(input_shape)\n",
        "\n",
        "# build convnet to use in each siamese 'leg'\n",
        "convnet = Sequential()\n",
        "\n",
        "convnet.add(Conv2D(64, (5,5), input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(LeakyReLU(alpha=0.1))\n",
        "convnet.add(MaxPooling2D())\n",
        "\n",
        "convnet.add(Conv2D(128, (3,3), input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(LeakyReLU(alpha=0.1))\n",
        "convnet.add(MaxPooling2D())\n",
        "\n",
        "convnet.add(Conv2D(256, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "convnet.add(Conv2D(256, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
        "convnet.add(BatchNormalization())\n",
        "convnet.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "convnet.add(Flatten())\n",
        "\n",
        "convnet.add(Dense(128, kernel_regularizer=l2(1e-3)))\n",
        "convnet.summary()\n",
        "\n",
        "# encode each of the two inputs into a vector with the convnet\n",
        "encoded_l = convnet(left_input)\n",
        "encoded_r = convnet(right_input)\n",
        "\n",
        "# merge two encoded inputs with the L1 distance between them, and connect \n",
        "#to prediction output layer\n",
        "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
        "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
        "prediction = Dense(1, activation='sigmoid')(both)\n",
        "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
        "\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.00001)\n",
        "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "\n",
        "\n",
        "siamese_net.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 14:58:06.599189 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 14:58:06.646044 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 14:58:06.656705 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 14:58:06.706733 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0718 14:58:06.707831 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0718 14:58:09.732799 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0718 14:58:09.798294 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 64)        4864      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "=================================================================\n",
            "Total params: 2,146,560\n",
            "Trainable params: 2,145,152\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0718 14:58:10.747190 140106542684032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 14:58:10.756735 140106542684032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 128)          2146560     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 128)          0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,146,689\n",
            "Trainable params: 2,145,281\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGvEryjAluBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "72c7b953-de70-44ba-8a58-b9b8ed0a7a43"
      },
      "source": [
        "# show model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(siamese_net, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"304pt\" viewBox=\"0.00 0.00 536.00 304.00\" width=\"536pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 532,-300 532,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140105247237288 -->\n<g class=\"node\" id=\"node1\">\n<title>140105247237288</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 255,-295.5 255,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"40\" y=\"-268.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"80,-249.5 80,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"80,-272.5 138,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"138,-249.5 138,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-280.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"138,-272.5 255,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-257.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 140105247237792 -->\n<g class=\"node\" id=\"node3\">\n<title>140105247237792</title>\n<polygon fill=\"none\" points=\"137.5,-166.5 137.5,-212.5 389.5,-212.5 389.5,-166.5 137.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-185.8\">Sequential</text>\n<polyline fill=\"none\" points=\"214.5,-166.5 214.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"214.5,-189.5 272.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"272.5,-166.5 272.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"331\" y=\"-197.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"272.5,-189.5 389.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"331\" y=\"-174.3\">(None, 128)</text>\n</g>\n<!-- 140105247237288&#45;&gt;140105247237792 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140105247237288-&gt;140105247237792</title>\n<path d=\"M165.3836,-249.3799C181.3128,-239.6583 200.0052,-228.2505 216.7771,-218.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"218.6353,-220.9811 225.3479,-212.784 214.9886,-215.0059 218.6353,-220.9811\" stroke=\"#000000\"/>\n</g>\n<!-- 140105247237344 -->\n<g class=\"node\" id=\"node2\">\n<title>140105247237344</title>\n<polygon fill=\"none\" points=\"273,-249.5 273,-295.5 528,-295.5 528,-249.5 273,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313\" y=\"-268.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"353,-249.5 353,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"353,-272.5 411,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"411,-249.5 411,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-280.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"411,-272.5 528,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-257.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 140105247237344&#45;&gt;140105247237792 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140105247237344-&gt;140105247237792</title>\n<path d=\"M362.3379,-249.3799C346.2915,-239.6583 327.4617,-228.2505 310.5664,-218.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"312.2991,-214.9722 301.9326,-212.784 308.6719,-220.9592 312.2991,-214.9722\" stroke=\"#000000\"/>\n</g>\n<!-- 140105054844240 -->\n<g class=\"node\" id=\"node4\">\n<title>140105054844240</title>\n<polygon fill=\"none\" points=\"115.5,-83.5 115.5,-129.5 411.5,-129.5 411.5,-83.5 115.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.5\" y=\"-102.8\">Lambda</text>\n<polyline fill=\"none\" points=\"179.5,-83.5 179.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"179.5,-106.5 237.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"237.5,-83.5 237.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-114.3\">[(None, 128), (None, 128)]</text>\n<polyline fill=\"none\" points=\"237.5,-106.5 411.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 140105247237792&#45;&gt;140105054844240 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140105247237792-&gt;140105054844240</title>\n<path d=\"M263.5,-166.3799C263.5,-158.1745 263.5,-148.7679 263.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"267.0001,-139.784 263.5,-129.784 260.0001,-139.784 267.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140104724253832 -->\n<g class=\"node\" id=\"node5\">\n<title>140104724253832</title>\n<polygon fill=\"none\" points=\"165,-.5 165,-46.5 362,-46.5 362,-.5 165,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"217,-.5 217,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-23.5 275,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-.5 275,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"275,-23.5 362,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140105054844240&#45;&gt;140104724253832 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140105054844240-&gt;140104724253832</title>\n<path d=\"M263.5,-83.3799C263.5,-75.1745 263.5,-65.7679 263.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"267.0001,-56.784 263.5,-46.784 260.0001,-56.784 267.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "217IFEv1l3wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, X):\n",
        "    \"\"\"Create pairs of (test image, support set image) with ground truth, for \n",
        "    testing N-way one-shot learning.\"\"\"\n",
        "    n_classes, n_examples, w, h, d = X.shape\n",
        "    indices = np.random.randint(0, n_examples, size=(N,))\n",
        "    \n",
        "    categories = np.random.choice(range(n_classes), size=(N,), replace=False) \n",
        "    \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
        "    test_image = np.asarray([X[true_category, ex1, :, :, :]]*N).reshape(N, w, h, 3)\n",
        "    support_set = X[categories, indices, :, :, :]\n",
        "    support_set[0, :, :, :] = X[true_category, ex2]\n",
        "    support_set = support_set.reshape(N, w, h, 3)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image, support_set]\n",
        "    return pairs, targets\n",
        "\n",
        "def test_oneshot(model, X, N=20, k=250, verbose=True):\n",
        "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over\n",
        "    k one-shot tasks.\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {}-way one-shot \" \n",
        "              \"learning tasks ...\".format(k, N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N, X)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct += 1\n",
        "    percent_correct = (100.0*n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\"\n",
        "              .format(percent_correct, N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8Vs63Epl5E7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d9bbb7e-19f9-431c-cd11-229c90ac58cb"
      },
      "source": [
        "loops = 100\n",
        "best_acc = 0\n",
        "for i in range(loops):\n",
        "    print(\"=== Training loop {} ===\".format(i+1))\n",
        "    train(siamese_net, x_train)\n",
        "    test_acc = test_oneshot(siamese_net, x_validation)\n",
        "    if test_acc >= best_acc:\n",
        "        print(\"********* New best one-shot accuracy, saving model ********\")\n",
        "        siamese_net.save(os.path.join(\".\", \"siamese.h5\"))\n",
        "        best_acc = test_acc"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Training loop 1 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0760\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 2 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0536\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.0% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 3 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0382\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 4 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0241\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 5 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0121\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 6 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0014\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 7 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.9925\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 8 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9834\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 9 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9761\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 10 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9719\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 11 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.9643\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 12 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9604\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 13 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.9547\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 14 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9479\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 15 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9450\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 16 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.9370\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 17 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9336\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 18 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9274\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 19 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9196\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 20 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9198\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 21 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9094\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 22 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.9064\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 23 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9072\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 24 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9002\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 25 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.8941\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 26 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8884\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 27 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8860\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 28 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8818\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 29 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8792\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 30 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8729\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 31 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8702\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 32 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8676\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 33 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8654\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 34 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8607\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 35 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8554\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 36 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8553\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 37 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8455\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 38 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8504\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 39 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8431\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 40 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8411\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 41 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8374\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 42 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8358\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 43 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8317\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 44 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8309\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 45 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8262\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 46 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8219\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 47 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8201\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 48 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8126\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 49 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8131\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 50 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8095\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 51 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8091\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 52 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8072\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 53 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8030\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 54 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7985\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 55 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7947\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 56 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7902\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 57 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7891\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 58 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7901\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 59 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7836\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 60 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.7813\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 61 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7784\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 62 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7759\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 20.4% accuracy for 20-way one-shot learning\n",
            "********* New best one-shot accuracy, saving model ********\n",
            "=== Training loop 63 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.7725\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 64 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7702\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 65 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7675\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 66 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7697\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 67 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7618\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 68 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7629\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 69 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7585\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 70 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7575\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 71 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7538\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 72 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7507\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 73 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7495\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 74 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.7460\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 75 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7415\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 76 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7452\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 77 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7395\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 78 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7359\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 79 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7399\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 80 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7323\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 81 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7301\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 82 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7271\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 83 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7294\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 84 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7241\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 85 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7223\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
            "=== Training loop 86 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7196\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 87 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7226\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 88 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7129\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 89 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7113\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 90 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7099\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 91 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.7104\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 92 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7095\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 93 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7016\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 94 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7068\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 95 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7027\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 96 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6981\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
            "=== Training loop 97 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6956\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
            "=== Training loop 98 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6965\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
            "=== Training loop 99 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6938\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
            "=== Training loop 100 ===\n",
            "Epoch 1/1\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6905\n",
            "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
            "Got an average of 13.2% accuracy for 20-way one-shot learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF6SUnEOmLy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bb4a10d5-ee1f-481e-f8cc-f8f7f19e0147"
      },
      "source": [
        "print('Best accuracy obtained after',loops,'loops of 1 epoch each:')\n",
        "print(best_acc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy obtained after 100 loops of 1 epoch each:\n",
            "20.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pglcNnnoTAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}